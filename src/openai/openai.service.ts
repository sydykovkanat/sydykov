import { Injectable, Logger, OnModuleInit } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import { readFileSync } from 'fs';
import OpenAI from 'openai';
import type { ChatCompletionMessageParam } from 'openai/resources/chat/completions';
import { join } from 'path';

export type MessageContent =
  | string
  | Array<
      | { type: 'text'; text: string }
      | { type: 'image_url'; image_url: { url: string } }
    >;

export interface ChatMessage {
  role: 'system' | 'user' | 'assistant';
  content: MessageContent;
}

export interface AIResponse {
  responseType: 'reaction' | 'text';
  content: string; // Emoji (üëç‚ù§Ô∏èüî•üéâüëèüòÅ) or text response
}

@Injectable()
export class OpenAIService implements OnModuleInit {
  private readonly logger = new Logger(OpenAIService.name);
  private client: OpenAI;
  private baseSystemPrompt: string;
  private readonly model: string;
  private readonly maxTokens: number;

  constructor(private readonly configService: ConfigService) {
    const apiKey = this.configService.get<string>('openai.apiKey');
    this.model = this.configService.get<string>('openai.model', 'gpt-4o-mini');
    this.maxTokens = this.configService.get<number>('openai.maxTokens', 1000);

    this.client = new OpenAI({
      apiKey,
    });
  }

  onModuleInit() {
    try {
      // –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –∏–∑ —Ñ–∞–π–ª–∞
      const promptPath = join(process.cwd(), 'base.prompt.txt');
      this.baseSystemPrompt = readFileSync(promptPath, 'utf-8');
      this.logger.log('Base system prompt loaded successfully');
    } catch (error) {
      this.logger.error('Failed to load base system prompt', error);
      throw error;
    }
  }

  /**
   * –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
   * –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç structured output —Å —Ç–∏–ø–æ–º –æ—Ç–≤–µ—Ç–∞ (—Ä–µ–∞–∫—Ü–∏—è –∏–ª–∏ —Ç–µ–∫—Å—Ç)
   */
  async generateResponse(messages: ChatMessage[]): Promise<AIResponse> {
    try {
      const systemMessage: ChatMessage = {
        role: 'system',
        content: this.baseSystemPrompt,
      };

      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: [systemMessage, ...messages] as ChatCompletionMessageParam[],
        max_tokens: this.maxTokens,
        temperature: 0.8,
        response_format: {
          type: 'json_schema',
          json_schema: {
            name: 'response_with_reaction',
            strict: true,
            schema: {
              type: 'object',
              properties: {
                responseType: {
                  type: 'string',
                  enum: ['reaction', 'text'],
                  description:
                    'Type of response: "reaction" for emoji reaction, "text" for text message',
                },
                content: {
                  type: 'string',
                  description:
                    'If responseType is "reaction", content MUST be EXACTLY one of these 6 emojis: üëç ‚ù§ üî• üéâ üëè üòÅ (NO OTHER EMOJIS ALLOWED, not even üëã or üôè). If responseType is "text", content is the text message in Russian.',
                },
              },
              required: ['responseType', 'content'],
              additionalProperties: false,
            },
          },
        },
      });

      const responseContent = completion.choices[0]?.message?.content;

      if (!responseContent) {
        throw new Error('No response from OpenAI');
      }

      // –ü–∞—Ä—Å–∏–º JSON –æ—Ç–≤–µ—Ç
      const aiResponse: AIResponse = JSON.parse(responseContent);

      this.logger.debug(
        `Generated ${aiResponse.responseType}: ${aiResponse.responseType === 'reaction' ? aiResponse.content : aiResponse.content.substring(0, 100) + '...'}`,
      );

      return aiResponse;
    } catch (error) {
      this.logger.error('Failed to generate response from OpenAI', error);
      throw error;
    }
  }

  /**
   * –°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ—Ç —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è —Å–∂–∞—Ç–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
   */
  async summarizeMessages(messages: ChatMessage[]): Promise<string> {
    try {
      const summaryPrompt: ChatMessage = {
        role: 'system',
        content: `–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —Å—É–º–º–∞—Ä–∏–∑–∏—Ä—É–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ–ø–∏—Å–∫–∏.
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî —Å–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, —Å–æ—Ö—Ä–∞–Ω—è—è –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã, —Ç–µ–º—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç.
–†–µ–∑—é–º–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º (–Ω–µ –±–æ–ª–µ–µ 300 —Å–ª–æ–≤), –Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º.`,
      };

      // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Ç–µ–∫—Å—Ç –¥–ª—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏
      const messageTexts = messages
        .map((m) => {
          const contentText =
            typeof m.content === 'string'
              ? m.content
              : m.content
                  .map((c) => (c.type === 'text' ? c.text : '[–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]'))
                  .join(' ');
          return `${m.role}: ${contentText}`;
        })
        .join('\n');

      const completion = await this.client.chat.completions.create({
        model: this.model,
        messages: [
          summaryPrompt,
          {
            role: 'user',
            content: `–°—É–º–º–∞—Ä–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è:\n\n${messageTexts}`,
          },
        ] as ChatCompletionMessageParam[],
        max_tokens: 500,
        temperature: 0.5,
      });

      const summary = completion.choices[0]?.message?.content;

      if (!summary) {
        throw new Error('No summary from OpenAI');
      }

      this.logger.debug(`Generated summary: ${summary.substring(0, 100)}...`);
      return summary;
    } catch (error) {
      this.logger.error('Failed to summarize messages', error);
      throw error;
    }
  }
}
